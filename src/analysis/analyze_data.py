#!/usr/bin/env python3
# -*- coding: utf-8 -*-


import pandas as pd
import numpy as np
import os
from collections import defaultdict

def analyze_all_datasets():
    """åˆ†ææ‰€æœ‰æ•°æ®é›†"""
    
    # å®šä¹‰æ‰€æœ‰æ•°æ®æ–‡ä»¶
    data_files = {
        'ä¼ä¸šåŸºæœ¬ä¿¡æ¯': '../../data/raw/01_ä¼ä¸šåŸºæœ¬ä¿¡æ¯.xlsx',
        'ä¿¡è´·ç”³è¯·æ•°æ®': '../../data/raw/02_ä¿¡è´·ç”³è¯·æ•°æ®.xlsx', 
        'è´¢åŠ¡æŠ¥è¡¨æ•°æ®': '../../data/raw/03_è´¢åŠ¡æŠ¥è¡¨æ•°æ®.xlsx',
        'ç¨åŠ¡è®°å½•': '../../data/raw/04_ç¨åŠ¡è®°å½•.xlsx',
        'é“¶è¡Œæµæ°´': '../../data/raw/05_é“¶è¡Œæµæ°´.xlsx',
        'ä¼ä¸šä¸»ä¿¡ç”¨æ•°æ®': '../../data/raw/06_ä¼ä¸šä¸»ä¿¡ç”¨æ•°æ®.xlsx',
        'è¡Œä¸šç»è¥çŠ¶å†µ': '../../data/raw/07_è¡Œä¸šç»è¥çŠ¶å†µ.xlsx',
        'ä¼ä¸šå¾ä¿¡æŠ¥å‘Š': '../../data/raw/08_ä¼ä¸šå¾ä¿¡æŠ¥å‘Š.xlsx',
        'ä¸Šä¸‹æ¸¸åˆä½œæƒ…å†µ': '../../data/raw/09_ä¸Šä¸‹æ¸¸åˆä½œæƒ…å†µ.xlsx',
        'ä¼ä¸šç»è¥é£é™©è¯„ä¼°': '../../data/raw/10_ä¼ä¸šç»è¥é£é™©è¯„ä¼°.xlsx',
        'åˆå¹¶ä¿¡è´·æ•°æ®': '../../data/raw/ä¸­å°ä¼ä¸šåˆå¹¶ä¿¡è´·æ•°æ®.xlsx'
    }
    
    all_columns = defaultdict(list)  # è®°å½•æ‰€æœ‰åˆ—ååŠå…¶å‡ºç°çš„æ–‡ä»¶
    text_columns = {}  # è®°å½•æ–‡æœ¬å‹åˆ—
    numeric_columns = {}  # è®°å½•æ•°å€¼å‹åˆ—
    dataset_info = {}  # è®°å½•æ¯ä¸ªæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯
    
    print("=== åˆ†ææ‰€æœ‰æ•°æ®é›† ===\n")
    
    for name, filename in data_files.items():
        if not os.path.exists(filename):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            continue
            
        try:
            df = pd.read_excel(filename)
            print(f"ğŸ“Š {name} ({filename})")
            print(f"   å½¢çŠ¶: {df.shape}")
            print(f"   åˆ—æ•°: {df.shape[1]}")
            
            # è®°å½•æ•°æ®é›†ä¿¡æ¯
            dataset_info[name] = {
                'filename': filename,
                'shape': df.shape,
                'columns': list(df.columns),
                'dtypes': df.dtypes.to_dict(),
                'missing_values': df.isnull().sum().to_dict(),
                'text_columns': [],
                'numeric_columns': [],
                'categorical_columns': []
            }
            
            # åˆ†ææ¯ä¸€åˆ—
            for col in df.columns:
                all_columns[col].append(name)
                
                # åˆ¤æ–­åˆ—ç±»å‹
                if df[col].dtype == 'object':
                    # æ–‡æœ¬å‹åˆ—
                    unique_values = df[col].nunique()
                    sample_values = df[col].dropna().unique()[:5]
                    
                    dataset_info[name]['text_columns'].append({
                        'column': col,
                        'unique_count': unique_values,
                        'sample_values': list(sample_values),
                        'missing_rate': df[col].isnull().mean()
                    })
                    
                    if col not in text_columns:
                        text_columns[col] = []
                    text_columns[col].append({
                        'dataset': name,
                        'unique_count': unique_values,
                        'sample_values': list(sample_values)
                    })
                    
                else:
                    # æ•°å€¼å‹åˆ—
                    dataset_info[name]['numeric_columns'].append({
                        'column': col,
                        'dtype': str(df[col].dtype),
                        'min': df[col].min() if not df[col].isnull().all() else None,
                        'max': df[col].max() if not df[col].isnull().all() else None,
                        'mean': df[col].mean() if not df[col].isnull().all() else None,
                        'missing_rate': df[col].isnull().mean()
                    })
                    
                    if col not in numeric_columns:
                        numeric_columns[col] = []
                    numeric_columns[col].append({
                        'dataset': name,
                        'dtype': str(df[col].dtype),
                        'stats': {
                            'min': df[col].min() if not df[col].isnull().all() else None,
                            'max': df[col].max() if not df[col].isnull().all() else None,
                            'mean': df[col].mean() if not df[col].isnull().all() else None
                        }
                    })
            
            print(f"   æ–‡æœ¬å‹åˆ—: {len(dataset_info[name]['text_columns'])}")
            print(f"   æ•°å€¼å‹åˆ—: {len(dataset_info[name]['numeric_columns'])}")
            print()
            
        except Exception as e:
            print(f"âŒ è¯»å– {filename} æ—¶å‡ºé”™: {e}\n")
    
    # åˆ†æé‡å¤åˆ—
    print("=== é‡å¤åˆ—åˆ†æ ===")
    duplicate_columns = {col: files for col, files in all_columns.items() if len(files) > 1}
    
    if duplicate_columns:
        for col, files in duplicate_columns.items():
            print(f"ğŸ“‹ '{col}' å‡ºç°åœ¨: {', '.join(files)}")
    else:
        print("âœ… æœªå‘ç°é‡å¤åˆ—å")
    
    print(f"\næ€»è®¡å‘ç° {len(duplicate_columns)} ä¸ªé‡å¤åˆ—å\n")
    
    # åˆ†ææ–‡æœ¬å‹æ•°æ®
    print("=== æ–‡æœ¬å‹æ•°æ®åˆ†æ ===")
    for col, info_list in text_columns.items():
        print(f"ğŸ“ {col}:")
        for info in info_list:
            print(f"   - {info['dataset']}: {info['unique_count']} ä¸ªå”¯ä¸€å€¼")
            print(f"     æ ·æœ¬å€¼: {info['sample_values']}")
    
    print(f"\næ€»è®¡ {len(text_columns)} ä¸ªæ–‡æœ¬å‹ç‰¹å¾\n")
    
    # è¯†åˆ«å¯èƒ½çš„æ ‡è¯†ç¬¦åˆ—
    print("=== æ ‡è¯†ç¬¦åˆ—è¯†åˆ« ===")
    id_keywords = ['id', 'ID', 'ç¼–å·', 'åç§°', 'å§“å', 'ä¼ä¸šå', 'æ³•äºº']
    potential_id_columns = []
    
    for col in all_columns.keys():
        if any(keyword in col for keyword in id_keywords):
            potential_id_columns.append(col)
    
    if potential_id_columns:
        print("ğŸ·ï¸  å¯èƒ½çš„æ ‡è¯†ç¬¦åˆ—:")
        for col in potential_id_columns:
            files = all_columns[col]
            print(f"   - {col} (å‡ºç°åœ¨: {', '.join(files)})")
    else:
        print("âœ… æœªå‘ç°æ˜æ˜¾çš„æ ‡è¯†ç¬¦åˆ—")
    
    print(f"\næ€»è®¡ {len(potential_id_columns)} ä¸ªå¯èƒ½çš„æ ‡è¯†ç¬¦åˆ—\n")
    
    # ä¿å­˜åˆ†æç»“æœ
    analysis_result = {
        'dataset_info': dataset_info,
        'duplicate_columns': duplicate_columns,
        'text_columns': text_columns,
        'numeric_columns': numeric_columns,
        'potential_id_columns': potential_id_columns
    }
    
    return analysis_result

if __name__ == "__main__":
    result = analyze_all_datasets()
    print("=== æ•°æ®é›†åˆ†æå®Œæˆ ===")